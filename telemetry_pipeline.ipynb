{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c526c4b1",
   "metadata": {},
   "source": [
    "# Telemetry Pipeline - Full Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e107d8f",
   "metadata": {},
   "source": [
    "This notebook covers the full pipeline for optical telemetry anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758f25a-8ef3-4162-a694-4097be74757e",
   "metadata": {},
   "source": [
    "                    GNU AFFERO GENERAL PUBLIC LICENSE\n",
    "                       Version 3, 19 November 2007\n",
    "\n",
    "Copyright (C) 2025 Shaji R. Nathan  \n",
    "IP Infusion Inc.  \n",
    "Email: shaji.nathan@ipinfusion.com  \n",
    "\n",
    "This program is free software: you can redistribute it and/or modify  \n",
    "it under the terms of the GNU Affero General Public License as  \n",
    "published by the Free Software Foundation, either version 3 of the  \n",
    "License, or (at your option) any later version.  \n",
    "\n",
    "This program is distributed in the hope that it will be useful,  \n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of  \n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the  \n",
    "GNU Affero General Public License for more details.  \n",
    "\n",
    "You should have received a copy of the GNU Affero General Public License  \n",
    "along with this program. If not, see <https://www.gnu.org/licenses/>.  \n",
    "\n",
    "As per AGPLv3, if you modify this software and make it available over a  \n",
    "network, you must provide the source code of your modifications under the  \n",
    "same license.  \n",
    "\n",
    "For inquiries, please contact:  \n",
    "Shaji R. Nathan  \n",
    "IP Infusion Inc.  \n",
    "Email: shaji.nathan@ipinfusion.com  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_synthetic_switch_telemetry(num_samples=200):\n",
    "    np.random.seed(42)\n",
    "    start_time = datetime.now()\n",
    "    timestamps = [start_time - timedelta(minutes=5 * i) for i in range(num_samples)]\n",
    "    names = [f\"QSFP-{i%32+1}\" for i in range(num_samples)]\n",
    "\n",
    "    data = {\n",
    "        'timestamp': timestamps,\n",
    "        'name': names,\n",
    "        'temp': np.random.uniform(20, 80, num_samples),\n",
    "        'trans-volt': np.random.uniform(3.2, 3.5, num_samples)\n",
    "    }\n",
    "\n",
    "    for ch in range(1, 5):\n",
    "        data[f'channel_{ch}_in_pwr'] = np.random.uniform(-3, 3, num_samples)\n",
    "        data[f'channel_{ch}_out_pwr'] = np.random.uniform(-3, 3, num_samples)\n",
    "        data[f'channel_{ch}_laser_bias_cur'] = np.random.uniform(5, 10, num_samples)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = df['timestamp'].astype(str)\n",
    "    df.to_csv('synthetic_switch_telemetry.csv', index=False)\n",
    "    return df\n",
    "\n",
    "df = generate_synthetic_switch_telemetry()\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fcdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "def classify_anomaly(row):\n",
    "    anomalies = []\n",
    "    if row['temp'] > 75:\n",
    "        anomalies.append(\"Overheating\")\n",
    "    if row['trans-volt'] < 3.1 or row['trans-volt'] > 3.5:\n",
    "        anomalies.append(\"Voltage Drift\")\n",
    "    for ch in range(1, 5):\n",
    "        if row[f'channel_{ch}_laser_bias_cur'] > 9:\n",
    "            anomalies.append(f\"Channel {ch} Bias Current Spike\")\n",
    "        if row[f'channel_{ch}_out_pwr'] < -3:\n",
    "            anomalies.append(f\"Channel {ch} Power Loss\")\n",
    "    return \"Anomalous - \" + ', '.join(anomalies) if anomalies else \"Normal\"\n",
    "\n",
    "def row_to_prompt(row):\n",
    "    prompt = (\n",
    "        f\"Telemetry Report:\\n\"\n",
    "        f\"- Timestamp: {row['timestamp']}\\n\"\n",
    "        f\"- Module: {row['name']}\\n\"\n",
    "        f\"- Temperature: {row['temp']:.2f}°C\\n\"\n",
    "        f\"- Transceiver Voltage: {row['trans-volt']:.2f}V\\n\"\n",
    "    )\n",
    "    for ch in range(1, 5):\n",
    "        prompt += (\n",
    "            f\"- Channel {ch} Input Power: {row[f'channel_{ch}_in_pwr']:.2f} dBm\\n\"\n",
    "            f\"- Channel {ch} Output Power: {row[f'channel_{ch}_out_pwr']:.2f} dBm\\n\"\n",
    "            f\"- Channel {ch} Laser Bias Current: {row[f'channel_{ch}_laser_bias_cur']:.2f} mA\\n\"\n",
    "        )\n",
    "    prompt += \"\\nIs this normal or anomalous?\"\n",
    "    return prompt\n",
    "\n",
    "with open('train.jsonl', 'w') as f:\n",
    "    for _, row in df.iterrows():\n",
    "        json.dump({\"prompt\": row_to_prompt(row), \"response\": classify_anomaly(row)}, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"✅ train.jsonl created.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef50ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset and split into train and validation\n",
    "dataset = load_dataset('json', data_files={'train': 'train.jsonl'})\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "model_name = 'mistralai/Mistral-7B-v0.1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"prompt\"], text_target=examples[\"response\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"fine_tuned_llama_telemetry\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_llama_telemetry\")\n",
    "print(\"✅ Fine-tuned model saved.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
